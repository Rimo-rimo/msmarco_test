{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pymilvus import model\n",
    "from pymilvus import MilvusClient, Collection, connections, DataType, CollectionSchema, FieldSchema\n",
    "import numpy as np\n",
    "import json\n",
    "from FlagEmbedding import FlagReranker\n",
    "from pymilvus.model.reranker import BGERerankFunction\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset load\n",
    "data = pd.read_csv(\"/home/livin/rimo/llm/msmarco/data/top1000_dev.tsv\", sep='\\t', names=['qid', 'pid', 'query', 'passage'])\n",
    "unique_query = pd.read_csv(\"/home/livin/rimo/llm/msmarco/notebook/unique_query.csv\")\n",
    "qrels = pd.read_csv(\"/home/livin/rimo/llm/msmarco/data/qrels.dev.small.tsv\", sep='\\t', names=['qid', 'r', 'pid', 'l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/livin/rimo/llm/msmarco_test/data/train_pid_list.pkl', 'wb') as file:\n",
    "#     pickle.dump(train_pid_list, file)\n",
    "\n",
    "# with open('/home/livin/rimo/llm/msmarco_test/data/test_pid_list.pkl', 'wb') as file:\n",
    "#     pickle.dump(test_pid_list, file)\n",
    "\n",
    "# print(\"변수가 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/livin/rimo/llm/msmarco_test/data/all_pid_list.pkl', 'rb') as file:\n",
    "    all_pid_list = pickle.load(file)\n",
    "with open('/home/livin/rimo/llm/msmarco_test/data/train_pid_list.pkl', 'rb') as file:\n",
    "    train_pid_list = pickle.load(file)\n",
    "with open('/home/livin/rimo/llm/msmarco_test/data/test_pid_list.pkl', 'rb') as file:\n",
    "    test_pid_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split train data\n",
    "# file_name_list = [\"kw_3_easy\",\"kw_3_hard\",\"kw_5_easy\",\"kw_5_hard\",\"kw_7_easy\",\"kw_7_hard\",\"kw_9_easy\",\"kw_9_hard\"]\n",
    "\n",
    "# for file_name in file_name_list:\n",
    "# \tfile_path = f\"/home/livin/rimo/llm/msmarco_test/data/{file_name}.jsonl\"\n",
    "# \tre = []\n",
    "# \twith open(file_path, 'r', encoding='utf-8') as file:\n",
    "# \t\tfor n, line in enumerate(file):\n",
    "# \t\t\tre.append(json.loads(line))\n",
    "\t\t\t\n",
    "# \tre = re[:5288]\n",
    "\t\t\t\n",
    "# \twith open(f\"/home/livin/rimo/llm/msmarco_test/data/{file_name}_train.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \t\tfor i in re: file.write(json.dumps(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Keywords Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80df30e7fdff404eaec242e9fdf39533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kw_model = KeyBERT(\"BAAI/bge-m3\")\n",
    "\n",
    "bge_m3_ef = model.hybrid.BGEM3EmbeddingFunction(\n",
    "        model_name= \"BAAI/bge-m3\",\n",
    "        batch_size = 16,\n",
    "        device = \"cuda:1\",\n",
    "        # use_fp16 = True,\n",
    "        return_dense = True,\n",
    "        return_sparse = False,\n",
    "        return_colbert_vecs = False,\n",
    "    )\n",
    "\n",
    "client = MilvusClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_list = data[\"pid\"].tolist()\n",
    "\n",
    "def get_random_pid(pid_list, exclude_pid, total_numbers):\n",
    "    pid_list_rerange = [pid for pid in pid_list if pid != exclude_pid]  # 제외할 숫자 제거\n",
    "    random_numbers = random.sample(pid_list_rerange, total_numbers) \n",
    "    return random_numbers\n",
    "\n",
    "def get_keyword_query(top_n, negative_type):\n",
    "    train_json = []\n",
    "    for pid in tqdm(train_pid_list):\n",
    "        passage = data[data[\"pid\"] == pid][\"passage\"].tolist()[0]\n",
    "\n",
    "        passage_keywords = kw_model.extract_keywords(passage, keyphrase_ngram_range=(1,1), top_n=top_n)\n",
    "        passage_keywords = sorted(passage_keywords, key=lambda x: passage.find(x[0]))\n",
    "        query = \" \".join([i[0] for i in passage_keywords])\n",
    "\n",
    "        query_vectors = bge_m3_ef.encode_queries([query])[\"dense\"]\n",
    "\n",
    "        if negative_type == \"hard\":\n",
    "            res = client.search(\n",
    "                collection_name=\"msmarco_bgem3\",\n",
    "                data=query_vectors,\n",
    "                limit=10,\n",
    "                output_fields=[\"text\"],\n",
    "                anns_field=\"dense_vector\",\n",
    "                filter=f\"pid != {pid}\",\n",
    "            )\n",
    "            neg_list = [i[\"entity\"][\"text\"] for i in res[0]]\n",
    "            \n",
    "        elif negative_type == \"easy\":\n",
    "             neg_pid = get_random_pid(pid_list, pid, 10)\n",
    "             neg_list = [data[data[\"pid\"] == i][\"passage\"].tolist()[0] for i in neg_pid]\n",
    "\n",
    "        train_json.append({\n",
    "            \"query\": query, \n",
    "            \"pos\": passage, \n",
    "            \"neg\": neg_list\n",
    "                })\n",
    "        # break\n",
    "\n",
    "    return train_json\n",
    "\n",
    "def get_gt_query(negative_type):\n",
    "    train_json = []\n",
    "    for pid in tqdm(train_pid_list):\n",
    "        passage = data[data[\"pid\"] == pid][\"passage\"].tolist()[0]\n",
    "        qid = qrels[qrels[\"pid\"] == pid][\"qid\"].tolist()[0]\n",
    "        query = unique_query[unique_query[\"qid\"] == qid][\"query\"].tolist()[0]\n",
    "\n",
    "        # passage_keywords = kw_model.extract_keywords(passage, keyphrase_ngram_range=(1,1), top_n=top_n)\n",
    "        # passage_keywords = sorted(passage_keywords, key=lambda x: passage.find(x[0]))\n",
    "        # query = \" \".join([i[0] for i in passage_keywords])\n",
    "\n",
    "\n",
    "        if negative_type == \"hard\":\n",
    "            query_vectors = bge_m3_ef.encode_queries([query])[\"dense\"]\n",
    "            res = client.search(\n",
    "                collection_name=\"msmarco_bgem3\",\n",
    "                data=query_vectors,\n",
    "                limit=10,\n",
    "                output_fields=[\"text\"],\n",
    "                anns_field=\"dense_vector\",\n",
    "                filter=f\"pid != {pid}\",\n",
    "            )\n",
    "            neg_list = [i[\"entity\"][\"text\"] for i in res[0]]\n",
    "            \n",
    "        elif negative_type == \"easy\":\n",
    "             neg_pid = get_random_pid(pid_list, pid, 10)\n",
    "             neg_list = [data[data[\"pid\"] == i][\"passage\"].tolist()[0] for i in neg_pid]\n",
    "\n",
    "        train_json.append({\n",
    "            \"query\": query, \n",
    "            \"pos\": passage, \n",
    "            \"neg\": neg_list\n",
    "                })\n",
    "        # break\n",
    "    return train_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5288/5288 [48:49<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# re = get_keyword_query(3, \"hard\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_3_hard.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_keyword_query(3, \"easy\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_3_easy.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_keyword_query(5, \"hard\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_5_hard.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_keyword_query(5, \"easy\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_5_easy.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_keyword_query(7, \"hard\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_7_hard.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_keyword_query(7, \"easy\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_7_easy.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_keyword_query(9, \"hard\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_9_hard.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_keyword_query(9, \"easy\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/kw_9_easy.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "# re = get_gt_query(\"easy\")\n",
    "# with open(\"/home/livin/rimo/llm/msmarco_test/data/gt_easy_train.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "# \tfor i in re: file.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "re = get_gt_query(\"hard\")\n",
    "with open(\"/home/livin/rimo/llm/msmarco_test/data/gt_hard_train.jsonl\" , encoding= \"utf-8\",mode=\"w\") as file: \n",
    "\tfor i in re: file.write(json.dumps(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0715 17:59:23.985000 135470223644480 torch/distributed/run.py:757] \n",
      "W0715 17:59:23.985000 135470223644480 torch/distributed/run.py:757] *****************************************\n",
      "W0715 17:59:23.985000 135470223644480 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0715 17:59:23.985000 135470223644480 torch/distributed/run.py:757] *****************************************\n",
      "07/15/2024 17:59:28 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: True\n",
      "/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "07/15/2024 17:59:28 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n",
      "07/15/2024 17:59:28 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=True,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=4,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=6e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/home/livin/rimo/llm/msmarco_test/model/runs/Jul15_17-59-28_livin,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=100.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/home/livin/rimo/llm/msmarco_test/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/home/livin/rimo/llm/msmarco_test/model,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n",
      "07/15/2024 17:59:28 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='BAAI/bge-reranker-large', config_name=None, tokenizer_name=None, cache_dir=None)\n",
      "07/15/2024 17:59:28 - INFO - __main__ -   Data parameters DataArguments(train_data='/home/livin/rimo/llm/msmarco_test/data/dev_train.jsonl', train_group_size=4, max_len=512)\n",
      "/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Generating train split: 6610 examples [00:00, 27629.61 examples/s]\n",
      "  0%|                                                 | 0/41300 [00:00<?, ?it/s][rank1]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "{'loss': 3.5127, 'grad_norm': 24.30995750427246, 'learning_rate': 5.998983050847458e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0014, 'grad_norm': 0.13612228631973267, 'learning_rate': 5.997530266343826e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0033, 'grad_norm': 0.010034467093646526, 'learning_rate': 5.996077481840194e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007378663867712021, 'learning_rate': 5.994624697336562e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0007, 'grad_norm': 0.0006852777441963553, 'learning_rate': 5.99317191283293e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0, 'grad_norm': 0.019793812185525894, 'learning_rate': 5.991719128329298e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006822018185630441, 'learning_rate': 5.990266343825666e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0, 'grad_norm': 8.679519669385627e-05, 'learning_rate': 5.988813559322034e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0, 'grad_norm': 0.00044168837484903634, 'learning_rate': 5.987360774818402e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0003446197952143848, 'learning_rate': 5.98590799031477e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0, 'grad_norm': 0.023642929270863533, 'learning_rate': 5.984455205811138e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0001, 'grad_norm': 5.451326069305651e-05, 'learning_rate': 5.983002421307507e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0008, 'grad_norm': 5.85883462917991e-05, 'learning_rate': 5.981549636803874e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0, 'grad_norm': 0.0028484913054853678, 'learning_rate': 5.980096852300242e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0, 'grad_norm': 0.0012574015418067575, 'learning_rate': 5.97864406779661e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0, 'grad_norm': 3.266015846747905e-05, 'learning_rate': 5.977191283292978e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0, 'grad_norm': 2.8115411623730324e-05, 'learning_rate': 5.9757384987893464e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0054, 'grad_norm': 0.0001065240940079093, 'learning_rate': 5.9742857142857144e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0, 'grad_norm': 6.56956690363586e-05, 'learning_rate': 5.9728329297820824e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002574922109488398, 'learning_rate': 5.9713801452784505e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0, 'grad_norm': 0.00025231027393601835, 'learning_rate': 5.9699273607748185e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0, 'grad_norm': 0.00017156392277684063, 'learning_rate': 5.9684745762711865e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001539415243314579, 'learning_rate': 5.9670217917675546e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001054334279615432, 'learning_rate': 5.9655690072639226e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0, 'grad_norm': 0.00012444968160707504, 'learning_rate': 5.9641162227602906e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0, 'grad_norm': 0.00010313108214177191, 'learning_rate': 5.962663438256659e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0, 'grad_norm': 4.908154733129777e-05, 'learning_rate': 5.961210653753027e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0, 'grad_norm': 4.6074150304775685e-05, 'learning_rate': 5.959757869249395e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0, 'grad_norm': 4.837662709178403e-05, 'learning_rate': 5.9583050847457635e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0, 'grad_norm': 5.1844319386873394e-05, 'learning_rate': 5.956852300242131e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0, 'grad_norm': 4.509391146712005e-05, 'learning_rate': 5.955399515738499e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0, 'grad_norm': 4.673023067880422e-05, 'learning_rate': 5.953946731234867e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0, 'grad_norm': 4.6378045226447284e-05, 'learning_rate': 5.952493946731235e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0, 'grad_norm': 4.254426312400028e-05, 'learning_rate': 5.951041162227603e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0, 'grad_norm': 3.708399526658468e-05, 'learning_rate': 5.949588377723971e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0, 'grad_norm': 3.563481368473731e-05, 'learning_rate': 5.948135593220339e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0, 'grad_norm': 3.7136851460672915e-05, 'learning_rate': 5.946682808716707e-05, 'epoch': 0.9}\n",
      "{'loss': 0.0, 'grad_norm': 3.545519939507358e-05, 'learning_rate': 5.945230024213075e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0, 'grad_norm': 3.460407970123924e-05, 'learning_rate': 5.943777239709443e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0, 'grad_norm': 3.6560948501573876e-05, 'learning_rate': 5.942324455205812e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0, 'grad_norm': 3.020798430952709e-05, 'learning_rate': 5.940871670702179e-05, 'epoch': 0.99}\n",
      "{'loss': 0.0, 'grad_norm': 3.2574153010500595e-05, 'learning_rate': 5.939418886198547e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0, 'grad_norm': 3.4013126423815265e-05, 'learning_rate': 5.937966101694915e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0, 'grad_norm': 3.242482853238471e-05, 'learning_rate': 5.936513317191283e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0, 'grad_norm': 3.428992204135284e-05, 'learning_rate': 5.9350605326876514e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001254677481483668, 'learning_rate': 5.93360774818402e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0, 'grad_norm': 3.10994619212579e-05, 'learning_rate': 5.9321549636803874e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0, 'grad_norm': 3.256724085076712e-05, 'learning_rate': 5.9307021791767555e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0, 'grad_norm': 2.85186088149203e-05, 'learning_rate': 5.9292493946731235e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0, 'grad_norm': 0.007514445576816797, 'learning_rate': 5.9277966101694916e-05, 'epoch': 1.21}\n",
      "  1%|▍                                   | 500/41300 [08:02<11:00:46,  1.03it/s]07/15/2024 18:07:36 - INFO - FlagEmbedding.reranker.trainer -   Saving model checkpoint to /home/livin/rimo/llm/msmarco_test/model/checkpoint-500\n",
      "{'loss': 0.0, 'grad_norm': 3.290146923973225e-05, 'learning_rate': 5.92634382566586e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0, 'grad_norm': 3.0336705094669014e-05, 'learning_rate': 5.9248910411622276e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0, 'grad_norm': 2.812135426211171e-05, 'learning_rate': 5.923438256658596e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0, 'grad_norm': 2.8003934858134016e-05, 'learning_rate': 5.921985472154964e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0, 'grad_norm': 2.8938162358826958e-05, 'learning_rate': 5.920532687651332e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0, 'grad_norm': 2.9738836019532755e-05, 'learning_rate': 5.9190799031477e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0, 'grad_norm': 2.981374564114958e-05, 'learning_rate': 5.9176271186440685e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0, 'grad_norm': 2.812111415551044e-05, 'learning_rate': 5.916174334140436e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0, 'grad_norm': 2.8303356884862296e-05, 'learning_rate': 5.914721549636804e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0, 'grad_norm': 2.716307426453568e-05, 'learning_rate': 5.913268765133172e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0, 'grad_norm': 2.8566950277308933e-05, 'learning_rate': 5.91181598062954e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0, 'grad_norm': 2.6086077923537232e-05, 'learning_rate': 5.910363196125909e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0, 'grad_norm': 2.5685592845547944e-05, 'learning_rate': 5.908910411622276e-05, 'epoch': 1.53}\n",
      "{'loss': 0.0, 'grad_norm': 2.577187115093693e-05, 'learning_rate': 5.907457627118644e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0, 'grad_norm': 2.5229441234841943e-05, 'learning_rate': 5.906004842615012e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0, 'grad_norm': 2.6016559786512516e-05, 'learning_rate': 5.90455205811138e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0, 'grad_norm': 2.715130176511593e-05, 'learning_rate': 5.903099273607748e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0, 'grad_norm': 2.757938091235701e-05, 'learning_rate': 5.901646489104117e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0, 'grad_norm': 2.5512130378047004e-05, 'learning_rate': 5.900193704600484e-05, 'epoch': 1.67}\n",
      "{'loss': 0.0, 'grad_norm': 2.596645208541304e-05, 'learning_rate': 5.898740920096852e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0, 'grad_norm': 2.244529787276406e-05, 'learning_rate': 5.89728813559322e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0, 'grad_norm': 2.573486381152179e-05, 'learning_rate': 5.8958353510895884e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0, 'grad_norm': 2.1446136088343337e-05, 'learning_rate': 5.894382566585957e-05, 'epoch': 1.77}\n",
      "{'loss': 0.0, 'grad_norm': 2.283656613144558e-05, 'learning_rate': 5.892929782082325e-05, 'epoch': 1.79}\n",
      "{'loss': 0.0, 'grad_norm': 2.267324634885881e-05, 'learning_rate': 5.8914769975786925e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0, 'grad_norm': 2.2159201762406155e-05, 'learning_rate': 5.8900242130750605e-05, 'epoch': 1.84}\n",
      "{'loss': 0.0, 'grad_norm': 2.158044298994355e-05, 'learning_rate': 5.8885714285714285e-05, 'epoch': 1.86}\n",
      "{'loss': 0.0, 'grad_norm': 1.996026185224764e-05, 'learning_rate': 5.8871186440677966e-05, 'epoch': 1.89}\n",
      "{'loss': 0.0, 'grad_norm': 2.2393631297745742e-05, 'learning_rate': 5.885665859564165e-05, 'epoch': 1.91}\n",
      "{'loss': 0.0, 'grad_norm': 2.3423479433404282e-05, 'learning_rate': 5.8842130750605326e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0, 'grad_norm': 2.1074996766401455e-05, 'learning_rate': 5.882760290556901e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0, 'grad_norm': 2.114808012265712e-05, 'learning_rate': 5.881307506053269e-05, 'epoch': 1.99}\n",
      "{'loss': 0.0, 'grad_norm': 2.014613892242778e-05, 'learning_rate': 5.879854721549637e-05, 'epoch': 2.01}\n",
      "{'loss': 0.0, 'grad_norm': 2.165996193070896e-05, 'learning_rate': 5.8784019370460055e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0, 'grad_norm': 2.0776000383193605e-05, 'learning_rate': 5.8769491525423735e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0, 'grad_norm': 2.1208143152762204e-05, 'learning_rate': 5.875496368038741e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0, 'grad_norm': 2.0918461814289913e-05, 'learning_rate': 5.874043583535109e-05, 'epoch': 2.11}\n",
      "{'loss': 0.0, 'grad_norm': 1.868424988060724e-05, 'learning_rate': 5.872590799031477e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0, 'grad_norm': 0.00038176937960088253, 'learning_rate': 5.871138014527845e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0, 'grad_norm': 1.9030714611290023e-05, 'learning_rate': 5.869685230024214e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0, 'grad_norm': 1.9420131138758734e-05, 'learning_rate': 5.868232445520582e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0, 'grad_norm': 1.9868868548655882e-05, 'learning_rate': 5.866779661016949e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0, 'grad_norm': 1.9119421267532744e-05, 'learning_rate': 5.865326876513317e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0, 'grad_norm': 1.9668248569360003e-05, 'learning_rate': 5.863874092009685e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0, 'grad_norm': 2.0322810087236576e-05, 'learning_rate': 5.862421307506054e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0, 'grad_norm': 1.9547143892850727e-05, 'learning_rate': 5.860968523002422e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0, 'grad_norm': 1.9879518731613643e-05, 'learning_rate': 5.859515738498789e-05, 'epoch': 2.35}\n",
      "{'loss': 0.0, 'grad_norm': 0.00031429159571416676, 'learning_rate': 5.858062953995157e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0, 'grad_norm': 1.8969592929352075e-05, 'learning_rate': 5.856610169491525e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0, 'grad_norm': 1.825948857003823e-05, 'learning_rate': 5.8551573849878934e-05, 'epoch': 2.42}\n",
      "  2%|▊                                  | 1000/41300 [16:16<10:40:39,  1.05it/s]07/15/2024 18:15:50 - INFO - FlagEmbedding.reranker.trainer -   Saving model checkpoint to /home/livin/rimo/llm/msmarco_test/model/checkpoint-1000\n",
      "{'loss': 0.0, 'grad_norm': 1.897854781418573e-05, 'learning_rate': 5.853704600484262e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0, 'grad_norm': 1.8530397937865928e-05, 'learning_rate': 5.85225181598063e-05, 'epoch': 2.47}\n",
      "{'loss': 0.0, 'grad_norm': 1.7675676645012572e-05, 'learning_rate': 5.8507990314769975e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0, 'grad_norm': 1.853763751569204e-05, 'learning_rate': 5.8493462469733655e-05, 'epoch': 2.52}\n",
      "{'loss': 0.0, 'grad_norm': 1.830114888434764e-05, 'learning_rate': 5.8478934624697335e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0, 'grad_norm': 1.689140663074795e-05, 'learning_rate': 5.846440677966102e-05, 'epoch': 2.57}\n",
      "{'loss': 0.0, 'grad_norm': 1.7319380276603624e-05, 'learning_rate': 5.84498789346247e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0, 'grad_norm': 1.6690522897988558e-05, 'learning_rate': 5.843535108958838e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0, 'grad_norm': 1.8478733181837015e-05, 'learning_rate': 5.842082324455206e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0, 'grad_norm': 1.728623465169221e-05, 'learning_rate': 5.840629539951574e-05, 'epoch': 2.66}\n",
      "{'loss': 0.0, 'grad_norm': 1.7107675375882536e-05, 'learning_rate': 5.839176755447942e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0, 'grad_norm': 1.6431928088422865e-05, 'learning_rate': 5.8377239709443105e-05, 'epoch': 2.71}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001371541729895398, 'learning_rate': 5.8362711864406785e-05, 'epoch': 2.74}\n",
      "{'loss': 0.0, 'grad_norm': 1.68757851497503e-05, 'learning_rate': 5.834818401937046e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0, 'grad_norm': 0.00031229600426740944, 'learning_rate': 5.833365617433414e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0, 'grad_norm': 1.6575215340708382e-05, 'learning_rate': 5.831912832929782e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0, 'grad_norm': 1.7478967492934316e-05, 'learning_rate': 5.8304600484261507e-05, 'epoch': 2.83}\n",
      "{'loss': 0.0, 'grad_norm': 1.7547326933708973e-05, 'learning_rate': 5.829007263922519e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0, 'grad_norm': 1.5736986824776977e-05, 'learning_rate': 5.827554479418887e-05, 'epoch': 2.88}\n",
      "{'loss': 0.0, 'grad_norm': 1.6667072486598045e-05, 'learning_rate': 5.826101694915254e-05, 'epoch': 2.91}\n",
      "{'loss': 0.0, 'grad_norm': 1.655801861488726e-05, 'learning_rate': 5.824648910411622e-05, 'epoch': 2.93}\n",
      "{'loss': 0.0, 'grad_norm': 1.5433848602697253e-05, 'learning_rate': 5.82319612590799e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0, 'grad_norm': 1.6152811440406367e-05, 'learning_rate': 5.821743341404359e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0, 'grad_norm': 1.664577575866133e-05, 'learning_rate': 5.820290556900727e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0, 'grad_norm': 1.5757921573822387e-05, 'learning_rate': 5.818837772397094e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0, 'grad_norm': 1.650767444516532e-05, 'learning_rate': 5.817384987893462e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0, 'grad_norm': 1.5380026525235735e-05, 'learning_rate': 5.8159322033898303e-05, 'epoch': 3.08}\n",
      "{'loss': 0.0, 'grad_norm': 1.568034349475056e-05, 'learning_rate': 5.8144794188861984e-05, 'epoch': 3.1}\n",
      "{'loss': 0.0, 'grad_norm': 1.514502855570754e-05, 'learning_rate': 5.813026634382567e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0, 'grad_norm': 1.558594885864295e-05, 'learning_rate': 5.811573849878935e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0, 'grad_norm': 1.472005715186242e-05, 'learning_rate': 5.8101210653753025e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0, 'grad_norm': 2.5239762180717662e-05, 'learning_rate': 5.8086682808716705e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0, 'grad_norm': 1.4671389180875849e-05, 'learning_rate': 5.8072154963680386e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0, 'grad_norm': 1.4528284737025388e-05, 'learning_rate': 5.805762711864407e-05, 'epoch': 3.24}\n",
      "{'loss': 0.0, 'grad_norm': 1.5456944311154075e-05, 'learning_rate': 5.804309927360775e-05, 'epoch': 3.27}\n",
      "{'loss': 0.0, 'grad_norm': 1.48877943502157e-05, 'learning_rate': 5.8028571428571433e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0, 'grad_norm': 1.3690612831851467e-05, 'learning_rate': 5.801404358353511e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0, 'grad_norm': 1.3295594726514537e-05, 'learning_rate': 5.799951573849879e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0, 'grad_norm': 1.386244002787862e-05, 'learning_rate': 5.798498789346247e-05, 'epoch': 3.37}\n",
      "{'loss': 0.0, 'grad_norm': 1.3852487427357119e-05, 'learning_rate': 5.7970460048426155e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0, 'grad_norm': 1.3783238500764128e-05, 'learning_rate': 5.7955932203389835e-05, 'epoch': 3.41}\n",
      "{'loss': 0.0, 'grad_norm': 1.2777551091858186e-05, 'learning_rate': 5.794140435835351e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0, 'grad_norm': 1.4485617612081114e-05, 'learning_rate': 5.792687651331719e-05, 'epoch': 3.46}\n",
      "{'loss': 0.0, 'grad_norm': 1.3597283214039635e-05, 'learning_rate': 5.791234866828087e-05, 'epoch': 3.49}\n",
      "{'loss': 0.0, 'grad_norm': 1.4178548553900328e-05, 'learning_rate': 5.789782082324456e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0, 'grad_norm': 1.3208158634370193e-05, 'learning_rate': 5.788329297820824e-05, 'epoch': 3.54}\n",
      "{'loss': 0.0033, 'grad_norm': 0.011890091001987457, 'learning_rate': 5.786876513317192e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0002, 'grad_norm': 0.000708792416844517, 'learning_rate': 5.785423728813559e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0302, 'grad_norm': 0.0001625673467060551, 'learning_rate': 5.783970944309927e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0421, 'grad_norm': 0.0012434027157723904, 'learning_rate': 5.782518159806295e-05, 'epoch': 3.63}\n",
      "  4%|█▎                                 | 1500/41300 [24:29<10:46:28,  1.03it/s]07/15/2024 18:24:03 - INFO - FlagEmbedding.reranker.trainer -   Saving model checkpoint to /home/livin/rimo/llm/msmarco_test/model/checkpoint-1500\n",
      "{'loss': 0.0557, 'grad_norm': 9.231285366695374e-05, 'learning_rate': 5.781065375302664e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0086, 'grad_norm': 1.2364220310701057e-05, 'learning_rate': 5.779612590799032e-05, 'epoch': 3.68}\n",
      "{'loss': 0.7109, 'grad_norm': 0.7969500422477722, 'learning_rate': 5.778595641646489e-05, 'epoch': 3.7}\n",
      "{'loss': 1.4604, 'grad_norm': 1.7916591167449951, 'learning_rate': 5.7771428571428576e-05, 'epoch': 3.73}\n",
      "{'loss': 1.4063, 'grad_norm': 2.0485875606536865, 'learning_rate': 5.7756900726392256e-05, 'epoch': 3.75}\n",
      "{'loss': 1.2471, 'grad_norm': 4.499776363372803, 'learning_rate': 5.774237288135594e-05, 'epoch': 3.78}\n",
      "{'loss': 0.3683, 'grad_norm': inf, 'learning_rate': 5.772929782082325e-05, 'epoch': 3.8}\n",
      "{'loss': 0.6762, 'grad_norm': 39.298282623291016, 'learning_rate': 5.771622276029056e-05, 'epoch': 3.83}\n",
      "{'loss': 1.9329, 'grad_norm': 0.30160385370254517, 'learning_rate': 5.770169491525424e-05, 'epoch': 3.85}\n",
      "{'loss': 0.0142, 'grad_norm': 1.5271315574645996, 'learning_rate': 5.7687167070217915e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0787, 'grad_norm': 0.4672655165195465, 'learning_rate': 5.7672639225181596e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0324, 'grad_norm': 1.9850232035878435e-07, 'learning_rate': 5.765811138014528e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0468, 'grad_norm': 0.7755913734436035, 'learning_rate': 5.764358353510896e-05, 'epoch': 3.95}\n",
      "{'loss': 0.9486, 'grad_norm': 57.522430419921875, 'learning_rate': 5.7629055690072643e-05, 'epoch': 3.97}\n",
      "{'loss': 1.6458, 'grad_norm': 237.01393127441406, 'learning_rate': 5.761452784503632e-05, 'epoch': 4.0}\n",
      "{'loss': 0.5043, 'grad_norm': 1.274990439414978, 'learning_rate': 5.76e-05, 'epoch': 4.02}\n",
      "{'loss': 0.4567, 'grad_norm': 1.3058286905288696, 'learning_rate': 5.758547215496368e-05, 'epoch': 4.04}\n",
      "{'loss': 0.4263, 'grad_norm': 2.3224050998687744, 'learning_rate': 5.7570944309927365e-05, 'epoch': 4.07}\n",
      "{'loss': 0.2988, 'grad_norm': 1.6239922046661377, 'learning_rate': 5.7556416464891045e-05, 'epoch': 4.09}\n",
      "{'loss': 0.2088, 'grad_norm': 1.313708782196045, 'learning_rate': 5.7541888619854726e-05, 'epoch': 4.12}\n",
      "{'loss': 0.2231, 'grad_norm': 1.4792468547821045, 'learning_rate': 5.75273607748184e-05, 'epoch': 4.14}\n",
      "{'loss': 0.3073, 'grad_norm': 1.7999131679534912, 'learning_rate': 5.751283292978208e-05, 'epoch': 4.16}\n",
      "{'loss': 0.122, 'grad_norm': 0.6862388253211975, 'learning_rate': 5.749830508474577e-05, 'epoch': 4.19}\n",
      "{'loss': 0.1276, 'grad_norm': 0.6890332102775574, 'learning_rate': 5.748377723970945e-05, 'epoch': 4.21}\n",
      "{'loss': 0.1039, 'grad_norm': 0.2540821433067322, 'learning_rate': 5.746924939467313e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0995, 'grad_norm': 0.011042099446058273, 'learning_rate': 5.745472154963681e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0791, 'grad_norm': 0.692823588848114, 'learning_rate': 5.744019370460048e-05, 'epoch': 4.29}\n",
      "{'loss': 0.0691, 'grad_norm': 0.03319164365530014, 'learning_rate': 5.742566585956416e-05, 'epoch': 4.31}\n",
      "{'loss': 0.1188, 'grad_norm': 1.732588768005371, 'learning_rate': 5.741113801452785e-05, 'epoch': 4.33}\n",
      "{'loss': 0.1867, 'grad_norm': 2.9734411239624023, 'learning_rate': 5.739661016949153e-05, 'epoch': 4.36}\n",
      "{'loss': 0.0787, 'grad_norm': 0.9343703389167786, 'learning_rate': 5.738208232445521e-05, 'epoch': 4.38}\n",
      "{'loss': 0.117, 'grad_norm': 7.4300432205200195, 'learning_rate': 5.736755447941888e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0403, 'grad_norm': 0.3673448860645294, 'learning_rate': 5.7353026634382564e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0121, 'grad_norm': 0.1863352209329605, 'learning_rate': 5.733849878934625e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0744, 'grad_norm': 1.6894268989562988, 'learning_rate': 5.732397094430993e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0543, 'grad_norm': 0.167821004986763, 'learning_rate': 5.730944309927361e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0355, 'grad_norm': 0.014664665795862675, 'learning_rate': 5.729491525423729e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0417, 'grad_norm': 0.34647631645202637, 'learning_rate': 5.7280387409200965e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0547, 'grad_norm': 2.868070363998413, 'learning_rate': 5.7265859564164646e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0403, 'grad_norm': 0.2993505001068115, 'learning_rate': 5.725133171912833e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0961, 'grad_norm': 0.34617161750793457, 'learning_rate': 5.723680387409201e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0175, 'grad_norm': 0.01637195236980915, 'learning_rate': 5.7222276029055694e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0641, 'grad_norm': 2.3960533142089844, 'learning_rate': 5.7207748184019374e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0218, 'grad_norm': 0.2849288284778595, 'learning_rate': 5.719322033898305e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0284, 'grad_norm': 4.8351593017578125, 'learning_rate': 5.7178692493946735e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0744, 'grad_norm': 0.0023205955512821674, 'learning_rate': 5.7164164648910415e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0032, 'grad_norm': 0.14991047978401184, 'learning_rate': 5.7149636803874095e-05, 'epoch': 4.77}\n",
      "{'loss': 0.0108, 'grad_norm': 1.4244825839996338, 'learning_rate': 5.7135108958837776e-05, 'epoch': 4.79}\n",
      "{'loss': 0.0183, 'grad_norm': 0.1380460560321808, 'learning_rate': 5.712058111380145e-05, 'epoch': 4.82}\n",
      "{'loss': 0.0722, 'grad_norm': 0.0015334832714870572, 'learning_rate': 5.710605326876513e-05, 'epoch': 4.84}\n",
      "  5%|█▋                                 | 2000/41300 [32:44<10:22:43,  1.05it/s]07/15/2024 18:32:17 - INFO - FlagEmbedding.reranker.trainer -   Saving model checkpoint to /home/livin/rimo/llm/msmarco_test/model/checkpoint-2000\n",
      "{'loss': 0.0207, 'grad_norm': 2.6536402702331543, 'learning_rate': 5.709152542372882e-05, 'epoch': 4.87}\n",
      "{'loss': 0.0084, 'grad_norm': 0.7281767725944519, 'learning_rate': 5.70769975786925e-05, 'epoch': 4.89}\n",
      "{'loss': 0.142, 'grad_norm': 14.479186058044434, 'learning_rate': 5.706246973365618e-05, 'epoch': 4.92}\n",
      "{'loss': 0.0488, 'grad_norm': 0.0033801274839788675, 'learning_rate': 5.704794188861986e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0177, 'grad_norm': 1.161157488822937, 'learning_rate': 5.703341404358353e-05, 'epoch': 4.96}\n",
      "{'loss': 0.0766, 'grad_norm': 0.21935822069644928, 'learning_rate': 5.701888619854722e-05, 'epoch': 4.99}\n",
      "{'loss': 0.0195, 'grad_norm': 0.3253824710845947, 'learning_rate': 5.70043583535109e-05, 'epoch': 5.01}\n",
      "{'loss': 0.0183, 'grad_norm': 5.30920934677124, 'learning_rate': 5.698983050847458e-05, 'epoch': 5.04}\n",
      "{'loss': 0.032, 'grad_norm': 0.0017718891613185406, 'learning_rate': 5.697530266343826e-05, 'epoch': 5.06}\n",
      "{'loss': 0.0116, 'grad_norm': 1.6720197891118005e-05, 'learning_rate': 5.696077481840194e-05, 'epoch': 5.08}\n",
      "{'loss': 0.0359, 'grad_norm': 0.14364975690841675, 'learning_rate': 5.6946246973365614e-05, 'epoch': 5.11}\n",
      "{'loss': 0.022, 'grad_norm': 0.01601133681833744, 'learning_rate': 5.69317191283293e-05, 'epoch': 5.13}\n",
      "{'loss': 0.02, 'grad_norm': 0.0031782882288098335, 'learning_rate': 5.691719128329298e-05, 'epoch': 5.16}\n",
      "{'loss': 0.0097, 'grad_norm': 0.18860477209091187, 'learning_rate': 5.690266343825666e-05, 'epoch': 5.18}\n",
      "{'loss': 0.0427, 'grad_norm': 5.386843204498291, 'learning_rate': 5.688813559322034e-05, 'epoch': 5.21}\n",
      "{'loss': 0.0129, 'grad_norm': 2.1583402156829834, 'learning_rate': 5.6873607748184016e-05, 'epoch': 5.23}\n",
      "{'loss': 0.0012, 'grad_norm': 0.15182621777057648, 'learning_rate': 5.68590799031477e-05, 'epoch': 5.25}\n",
      "{'loss': 0.035, 'grad_norm': 0.14886370301246643, 'learning_rate': 5.684455205811138e-05, 'epoch': 5.28}\n",
      "{'loss': 0.028, 'grad_norm': 5.839509010314941, 'learning_rate': 5.683002421307506e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0006, 'grad_norm': 0.011147696524858475, 'learning_rate': 5.6815496368038744e-05, 'epoch': 5.33}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0003542830527294427, 'learning_rate': 5.6800968523002424e-05, 'epoch': 5.35}\n",
      "{'loss': 0.0043, 'grad_norm': 0.0268239863216877, 'learning_rate': 5.67864406779661e-05, 'epoch': 5.38}\n",
      "{'loss': 0.109, 'grad_norm': 7.34012508392334, 'learning_rate': 5.6771912832929785e-05, 'epoch': 5.4}\n",
      "{'loss': 0.0327, 'grad_norm': 0.7249855399131775, 'learning_rate': 5.6757384987893465e-05, 'epoch': 5.42}\n",
      "{'loss': 0.0062, 'grad_norm': 0.0012171432608738542, 'learning_rate': 5.6742857142857146e-05, 'epoch': 5.45}\n",
      "{'loss': 0.0116, 'grad_norm': 0.009703927673399448, 'learning_rate': 5.6728329297820826e-05, 'epoch': 5.47}\n",
      "{'loss': 0.0085, 'grad_norm': 0.0038822477217763662, 'learning_rate': 5.6713801452784506e-05, 'epoch': 5.5}\n",
      "{'loss': 0.0382, 'grad_norm': 0.10735087841749191, 'learning_rate': 5.669927360774818e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0074, 'grad_norm': 3.3156187534332275, 'learning_rate': 5.668474576271187e-05, 'epoch': 5.54}\n",
      "{'loss': 0.0034, 'grad_norm': 0.0077615357004106045, 'learning_rate': 5.667021791767555e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0022, 'grad_norm': 0.03405193239450455, 'learning_rate': 5.665569007263923e-05, 'epoch': 5.59}\n",
      "{'loss': 0.0382, 'grad_norm': 0.14514930546283722, 'learning_rate': 5.664116222760291e-05, 'epoch': 5.62}\n",
      "{'loss': 0.0094, 'grad_norm': 3.280998945236206, 'learning_rate': 5.662663438256658e-05, 'epoch': 5.64}\n",
      "{'loss': 0.0174, 'grad_norm': 1.2504429817199707, 'learning_rate': 5.661210653753027e-05, 'epoch': 5.67}\n",
      "{'loss': 0.0654, 'grad_norm': 0.004467868246138096, 'learning_rate': 5.659757869249395e-05, 'epoch': 5.69}\n",
      "{'loss': 0.0442, 'grad_norm': 1.641041874885559, 'learning_rate': 5.658305084745763e-05, 'epoch': 5.71}\n",
      "{'loss': 0.0011, 'grad_norm': 0.03603389114141464, 'learning_rate': 5.656852300242131e-05, 'epoch': 5.74}\n",
      "{'loss': 0.0039, 'grad_norm': 0.020532026886940002, 'learning_rate': 5.655399515738499e-05, 'epoch': 5.76}\n",
      "{'loss': 0.0014, 'grad_norm': 0.01116898562759161, 'learning_rate': 5.6539467312348664e-05, 'epoch': 5.79}\n",
      "{'loss': 0.0014, 'grad_norm': 0.13844627141952515, 'learning_rate': 5.652493946731235e-05, 'epoch': 5.81}\n",
      "{'loss': 0.0021, 'grad_norm': 0.4008168578147888, 'learning_rate': 5.651041162227603e-05, 'epoch': 5.84}\n",
      "{'loss': 0.017, 'grad_norm': 21.26593780517578, 'learning_rate': 5.649588377723971e-05, 'epoch': 5.86}\n",
      "{'loss': 0.0384, 'grad_norm': 0.002373875817283988, 'learning_rate': 5.648135593220339e-05, 'epoch': 5.88}\n",
      "  6%|██                                 | 2434/41300 [39:53<10:29:27,  1.03it/s][rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "[rank0]:     return _run_code(code, main_globals, None,\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "[rank0]:     exec(code, run_globals)\n",
      "[rank0]:   File \"/home/livin/rimo/llm/FlagEmbedding/FlagEmbedding/reranker/run.py\", line 95, in <module>\n",
      "[rank0]:     main()\n",
      "[rank0]:   File \"/home/livin/rimo/llm/FlagEmbedding/FlagEmbedding/reranker/run.py\", line 90, in main\n",
      "[rank0]:     trainer.train()\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py\", line 1859, in train\n",
      "[rank0]:     return inner_training_loop(\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py\", line 2203, in _inner_training_loop\n",
      "[rank0]:     tr_loss_step = self.training_step(model, inputs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py\", line 3138, in training_step\n",
      "[rank0]:     loss = self.compute_loss(model, inputs)\n",
      "[rank0]:   File \"/home/livin/rimo/llm/FlagEmbedding/FlagEmbedding/reranker/trainer.py\", line 31, in compute_loss\n",
      "[rank0]:     return model(inputs)['loss']\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1593, in forward\n",
      "[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1411, in _run_ddp_forward\n",
      "[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 822, in forward\n",
      "[rank0]:     return model_forward(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 810, in __call__\n",
      "[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      "[rank0]:     return func(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/rimo/llm/FlagEmbedding/FlagEmbedding/reranker/modeling.py\", line 34, in forward\n",
      "[rank0]:     ranker_out: SequenceClassifierOutput = self.hf_model(**batch, return_dict=True)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 1201, in forward\n",
      "[rank0]:     outputs = self.roberta(\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 830, in forward\n",
      "[rank0]:     encoder_outputs = self.encoder(\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 518, in forward\n",
      "[rank0]:     layer_outputs = layer_module(\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 407, in forward\n",
      "[rank0]:     self_attention_outputs = self.attention(\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 334, in forward\n",
      "[rank0]:     self_outputs = self.self(\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 264, in forward\n",
      "[rank0]:     attention_probs = self.dropout(attention_probs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/dropout.py\", line 59, in forward\n",
      "[rank0]:     return F.dropout(input, self.p, self.training, self.inplace)\n",
      "[rank0]:   File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "[rank0]:     return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "[rank0]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 78.00 MiB. GPU \n",
      "  6%|██                                 | 2434/41300 [39:53<10:37:01,  1.02it/s]\n",
      "W0715 18:39:30.940000 135470223644480 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 581859 closing signal SIGTERM\n",
      "E0715 18:39:31.156000 135470223644480 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 581858) of binary: /home/livin/anaconda3/envs/nlp/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/livin/anaconda3/envs/nlp/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/distributed/run.py\", line 879, in main\n",
      "    run(args)\n",
      "  File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/distributed/run.py\", line 870, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/livin/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 263, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "FlagEmbedding.reranker.run FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-07-15_18:39:30\n",
      "  host      : livin\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 581858)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node 2 -m FlagEmbedding.reranker.run --output_dir /home/livin/rimo/llm/msmarco_test/model --model_name_or_path BAAI/bge-reranker-large --train_data /home/livin/rimo/llm/msmarco_test/data/dev_train.jsonl --learning_rate 6e-5 --fp16 --num_train_epochs 100 --per_device_train_batch_size 2 --gradient_accumulation_steps 4 --dataloader_drop_last True --train_group_size 4 --max_len 512 --weight_decay 0.01 --logging_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f6858028604bf39cb95bb71ccdc073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bge_m3_ef = model.hybrid.BGEM3EmbeddingFunction(\n",
    "        model_name= \"BAAI/bge-m3\",\n",
    "        batch_size = 16,\n",
    "        device = \"cuda:0\",\n",
    "        # use_fp16 = True,\n",
    "        return_dense = True,\n",
    "        return_sparse = False,\n",
    "        return_colbert_vecs = False,\n",
    "    )\n",
    "bge_rf = BGERerankFunction(\n",
    "    # model_name=\"BAAI/bge-reranker-large\",  # Specify the model name. Defaults to `BAAI/bge-reranker-v2-m3`.\n",
    "    model_name=\"/home/livin/rimo/llm/msmarco_finetuning/model/checkpoint-7000\",\n",
    "    device=\"cuda:0\" # Specify the device to use, e.g., 'cpu' or 'cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MilvusClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 54/6980 [00:43<1:32:08,  1.25it/s]"
     ]
    }
   ],
   "source": [
    "unique_query = pd.read_csv('/home/livin/rimo/llm/msmarco/notebook/unique_query.csv')\n",
    "\n",
    "result = []\n",
    "error_list = []\n",
    "\n",
    "for i in tqdm(range(len(unique_query))):\n",
    "    try:\n",
    "        qid, query = unique_query.iloc[i][\"qid\"], unique_query.iloc[i][\"query\"]\n",
    "        query_vectors = bge_m3_ef.encode_queries([query])[\"dense\"]\n",
    "\n",
    "        candidate = client.search(\n",
    "            collection_name=\"msmarco_bgem3\",  # target collection\n",
    "            data=query_vectors,  # query vectors\n",
    "            limit=100,  # number of returned entities\n",
    "            # filter=f\"qid == {qid}\",\n",
    "            output_fields=[\"pid\",\"text\"],\n",
    "            anns_field=\"dense_vector\"\n",
    "        )\n",
    "        candidate_text = [i[\"entity\"][\"text\"] for i in candidate[0]]\n",
    "        candidate_pid = np.array([i[\"entity\"][\"pid\"] for i in candidate[0]])\n",
    "\n",
    "        top_k = bge_rf(\n",
    "            query=query,\n",
    "            documents=candidate_text,\n",
    "            top_k=100,\n",
    "        )\n",
    "        for n,i in enumerate(top_k):\n",
    "            result.append([qid, candidate_pid[i.index], n+1])\n",
    "    except:\n",
    "        error_list.append(qid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "\n",
    "tsv_file_path = '/home/livin/rimo/llm/msmarco_finetuning/result/ms_triplet_7000.tsv'\n",
    "result_df.to_csv(tsv_file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
